{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc4627608d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.tag import untag\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged:  [('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')]\n",
      "___________________________\n",
      "\n",
      "Untagged:  ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "source": [
    "brown_news_tagged = brown.tagged_sents(categories='news', tagset='universal')\n",
    "brown_news_words = brown.tagged_words(categories='news', tagset='universal')\n",
    "\n",
    "brown_train = brown_news_tagged[100:]\n",
    "brown_test = brown_news_tagged[:100]\n",
    "test_sent = untag(brown_test[0])\n",
    "print(\"Tagged: \", brown_test[0])\n",
    "print('___________________________\\n')\n",
    "print(\"Untagged: \", test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(brown_dataset):\n",
    "    training_data = []\n",
    "    for sent in brown_dataset:\n",
    "        untaged_sent = untag(sent)\n",
    "        tags = [tag for _,tag in sent]\n",
    "        training_data.append((untaged_sent,tags))\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_to_ix(training_data):\n",
    "    to_ix = {}\n",
    "    for sent, tags in training_data:\n",
    "        for word in sent:\n",
    "            if word not in to_ix:\n",
    "                to_ix[word] = len(to_ix)\n",
    "    return to_ix\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    # A tuple of (values, indices) is returned,\n",
    "    # where the indices are the indices of the elements in the original input tensor.\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i]\n",
    "\n",
    "def accuracy(real,pred):\n",
    "    correct = 0\n",
    "    N = 0\n",
    "    for i in range(len(real)):\n",
    "        for real_label,pred_label in zip(real[i],pred[i]):\n",
    "            if real_label == categoryFromOutput(pred_label):\n",
    "                    correct += 1\n",
    "        N += len(real[i])\n",
    "    return correct * 100 / N\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = reformat(brown_train)\n",
    "test_data = reformat(brown_test)\n",
    "\n",
    "word_to_ix = get_to_ix(training_data+test_data)\n",
    "\n",
    "tag_to_ix = {'ADJ':0,'ADP':1,'ADV':2,'CONJ':3,'DET':4,'NOUN':5,\n",
    "             'NUM':6,'PRT':7,'PRON':8,'VERB':9,'.':10,'X':11}\n",
    "\n",
    "all_categories = ['ADJ','ADP','ADV','CONJ','DET','NOUN',\n",
    "                 'NUM','PRT','PRON','VERB','.','X']\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, 1, self.hidden_dim).to('cuda'),\n",
    "                torch.zeros(1, 1, self.hidden_dim).to('cuda'))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3959, -2.6854, -2.5724, -2.9977, -2.3539, -2.7690, -2.0622,\n",
      "         -2.7923, -2.1698, -2.7879, -2.4779, -2.2199],\n",
      "        [-2.6655, -2.4565, -2.4383, -2.9171, -2.4000, -2.5787, -2.3422,\n",
      "         -2.9593, -2.2046, -2.5828, -2.1214, -2.4887],\n",
      "        [-2.5505, -2.8002, -2.9879, -2.9769, -2.3474, -2.7428, -2.4584,\n",
      "         -3.0217, -1.8872, -2.6414, -1.9625, -2.2804],\n",
      "        [-2.4983, -2.6355, -2.4682, -2.8517, -2.4176, -2.6173, -2.0370,\n",
      "         -2.7326, -2.3782, -2.6639, -2.5523, -2.2470],\n",
      "        [-2.6966, -2.5131, -2.5092, -2.7616, -2.4182, -2.2062, -2.4613,\n",
      "         -2.6251, -2.2857, -2.6084, -2.2523, -2.6657],\n",
      "        [-2.6895, -2.8626, -2.8727, -2.7660, -2.7094, -2.2310, -2.1871,\n",
      "         -2.4408, -2.0116, -2.6274, -2.2276, -2.6832],\n",
      "        [-2.6462, -2.7684, -2.7255, -2.7060, -2.5941, -2.3330, -2.1486,\n",
      "         -2.4944, -2.2237, -2.5893, -2.3577, -2.4632],\n",
      "        [-2.6363, -2.9015, -2.9608, -2.6441, -2.5465, -2.1891, -2.3132,\n",
      "         -2.4432, -2.1660, -2.5705, -2.3155, -2.4705],\n",
      "        [-2.8654, -2.7544, -2.8738, -2.7429, -2.6300, -2.0632, -2.5400,\n",
      "         -2.8365, -2.0669, -2.3866, -1.9314, -2.8399],\n",
      "        [-2.8027, -2.7150, -2.8813, -2.8615, -2.6210, -2.3938, -2.4781,\n",
      "         -2.7746, -1.8954, -2.5701, -1.8527, -2.7179],\n",
      "        [-2.6945, -2.7308, -2.5972, -2.6854, -2.6604, -2.3112, -2.0390,\n",
      "         -2.5709, -2.3515, -2.5031, -2.4271, -2.4823],\n",
      "        [-2.5781, -2.9764, -2.8839, -2.6028, -2.5925, -2.5493, -1.9605,\n",
      "         -2.5627, -2.4537, -2.5097, -2.6066, -2.0308],\n",
      "        [-2.7580, -2.8073, -2.6796, -2.6028, -2.7477, -2.2732, -2.0033,\n",
      "         -2.5423, -2.4014, -2.4253, -2.4298, -2.4555],\n",
      "        [-2.3340, -2.7950, -2.6254, -2.9220, -2.3648, -2.5664, -2.0135,\n",
      "         -2.5577, -2.2541, -2.8410, -2.7150, -2.2593],\n",
      "        [-2.5146, -2.7734, -2.7454, -2.7502, -2.4493, -2.5224, -2.1600,\n",
      "         -2.4582, -2.2443, -2.7262, -2.4733, -2.2519],\n",
      "        [-2.5618, -2.8426, -2.7981, -2.6984, -2.5505, -2.4648, -2.0886,\n",
      "         -2.4202, -2.2567, -2.6662, -2.4817, -2.2762],\n",
      "        [-2.5412, -2.7899, -2.8182, -2.7284, -2.4350, -2.5750, -2.2145,\n",
      "         -2.5298, -2.2256, -2.6762, -2.3804, -2.1823],\n",
      "        [-2.4214, -2.5764, -2.3982, -3.0119, -2.3561, -2.6638, -2.0643,\n",
      "         -2.7795, -2.2407, -2.7935, -2.5291, -2.3613],\n",
      "        [-2.3950, -2.6239, -2.2990, -3.0649, -2.3976, -3.0631, -1.7967,\n",
      "         -3.0240, -2.5219, -2.7722, -2.7922, -2.0172],\n",
      "        [-2.7630, -2.6412, -2.3906, -2.6840, -2.7221, -2.4164, -1.8994,\n",
      "         -2.7433, -2.5618, -2.4052, -2.5154, -2.4245],\n",
      "        [-2.7777, -2.5201, -2.2697, -2.5715, -2.5861, -2.1496, -2.1498,\n",
      "         -2.4680, -2.8046, -2.5204, -2.7279, -2.5487],\n",
      "        [-2.5999, -2.5460, -2.4096, -2.6655, -2.3820, -2.2378, -2.2959,\n",
      "         -2.3868, -2.5863, -2.7084, -2.6758, -2.4597],\n",
      "        [-2.6975, -2.5449, -2.4841, -2.8720, -2.5052, -2.6056, -2.1906,\n",
      "         -3.0255, -2.2425, -2.4683, -2.1380, -2.4142],\n",
      "        [-2.6151, -2.8897, -3.0442, -2.8407, -2.5671, -2.6656, -2.2716,\n",
      "         -2.6167, -1.8961, -2.6929, -2.0658, -2.3211],\n",
      "        [-2.5388, -2.8046, -2.9037, -2.7678, -2.4258, -2.7832, -2.2440,\n",
      "         -2.5436, -2.1497, -2.7441, -2.2969, -2.0664],\n",
      "        [-2.5717, -2.8016, -2.9011, -2.7655, -2.4788, -2.4922, -2.3150,\n",
      "         -2.4067, -2.0540, -2.7612, -2.2618, -2.3653],\n",
      "        [-2.5762, -3.0474, -3.2331, -2.8837, -2.6229, -2.8230, -2.1967,\n",
      "         -2.6119, -1.8009, -2.7490, -2.0756, -2.2085],\n",
      "        [-2.6266, -3.1435, -3.1288, -2.8783, -2.8728, -2.7238, -1.8292,\n",
      "         -2.6968, -1.8866, -2.5872, -2.2204, -2.3124],\n",
      "        [-2.5716, -2.7150, -2.6189, -2.7691, -2.5122, -2.4550, -2.0924,\n",
      "         -2.5960, -2.2783, -2.6195, -2.4387, -2.3615],\n",
      "        [-2.5928, -2.6249, -2.5794, -2.7003, -2.4165, -2.3374, -2.2905,\n",
      "         -2.4314, -2.3672, -2.6931, -2.4759, -2.4158],\n",
      "        [-2.5780, -2.7891, -2.7042, -2.6819, -2.5504, -2.4190, -2.0794,\n",
      "         -2.4014, -2.3364, -2.6606, -2.5384, -2.3125],\n",
      "        [-2.4250, -2.7799, -2.7373, -2.7732, -2.3214, -2.4500, -2.2304,\n",
      "         -2.4842, -2.2893, -2.7612, -2.5797, -2.2386],\n",
      "        [-2.5182, -3.0216, -3.1184, -2.6553, -2.4236, -2.1968, -2.3723,\n",
      "         -2.4681, -2.1462, -2.6059, -2.3941, -2.3395],\n",
      "        [-2.6174, -2.7392, -2.7259, -2.6937, -2.5271, -2.5502, -2.1485,\n",
      "         -2.4982, -2.2830, -2.6352, -2.3789, -2.2435],\n",
      "        [-2.5836, -2.7727, -2.4836, -2.9209, -2.7110, -2.5035, -1.7599,\n",
      "         -2.8651, -2.2679, -2.5237, -2.5164, -2.4898],\n",
      "        [-2.6876, -2.6573, -2.4753, -2.7497, -2.6139, -2.1838, -2.0899,\n",
      "         -2.6924, -2.3682, -2.4781, -2.4354, -2.6401]], device='cuda:0')\n",
      "ephoc 0\n",
      "ephoc 1\n",
      "ephoc 2\n",
      "ephoc 3\n",
      "ephoc 4\n",
      "ephoc 5\n",
      "ephoc 6\n",
      "ephoc 7\n",
      "ephoc 8\n",
      "ephoc 9\n",
      "tensor([[-2.4953e+00, -9.3856e+00, -4.2398e+00, -9.4662e+00, -1.0790e+01,\n",
      "         -4.7023e-01, -4.2125e+00, -8.6697e+00, -8.7117e+00, -1.3412e+00,\n",
      "         -1.0646e+01, -6.5856e+00],\n",
      "        [-5.3120e-01, -1.0473e+01, -2.0481e+00, -8.1843e+00, -4.5328e+00,\n",
      "         -1.6258e+00, -2.9286e+00, -1.0075e+01, -7.7692e+00, -4.0523e+00,\n",
      "         -7.2924e+00, -5.7095e+00],\n",
      "        [-2.5526e+00, -9.5376e+00, -5.6405e+00, -1.1074e+01, -8.1447e+00,\n",
      "         -1.2338e+00, -3.9155e+00, -8.5018e+00, -1.2284e+01, -5.0182e-01,\n",
      "         -8.1818e+00, -6.7481e+00],\n",
      "        [-8.9198e+00, -1.5494e+01, -1.2777e+01, -1.6943e+01, -1.4782e-04,\n",
      "         -1.5755e+01, -1.1519e+01, -1.7989e+01, -2.3300e+01, -1.9894e+01,\n",
      "         -1.4757e+01, -1.5452e+01],\n",
      "        [-3.3738e+00, -6.6841e+00, -6.2297e+00, -1.2257e+01, -1.4848e+01,\n",
      "         -1.3056e-01, -6.4313e+00, -8.6456e+00, -1.2331e+01, -2.4906e+00,\n",
      "         -1.7928e+01, -8.2445e+00],\n",
      "        [-8.2674e+00, -1.1644e-03, -7.3032e+00, -2.0862e+01, -1.1670e+01,\n",
      "         -1.0630e+01, -1.0335e+01, -8.7014e+00, -1.6974e+01, -1.6506e+01,\n",
      "         -2.2314e+01, -1.3185e+01],\n",
      "        [-9.2095e+00, -1.6054e+01, -1.3087e+01, -1.6651e+01, -1.1349e-04,\n",
      "         -1.5920e+01, -1.1452e+01, -1.8132e+01, -2.2856e+01, -1.9911e+01,\n",
      "         -1.4215e+01, -1.5536e+01],\n",
      "        [-2.7686e+00, -9.9711e+00, -5.5678e+00, -1.3171e+01, -1.4618e+01,\n",
      "         -7.7983e-02, -5.4382e+00, -1.2273e+01, -7.8490e+00, -5.6655e+00,\n",
      "         -1.5773e+01, -8.5312e+00],\n",
      "        [-1.1740e+01, -1.5875e+01, -9.2885e+00, -1.4481e+01, -9.6244e+00,\n",
      "         -1.2078e+01, -6.5616e+00, -1.0813e+01, -8.8862e+00, -7.4793e+00,\n",
      "         -2.3232e-03, -1.1453e+01],\n",
      "        [-5.2942e+00, -9.4150e+00, -4.0767e+00, -6.7750e+00, -2.4158e-02,\n",
      "         -1.0749e+01, -7.7178e+00, -9.4140e+00, -1.3815e+01, -1.1800e+01,\n",
      "         -1.1699e+01, -9.2522e+00],\n",
      "        [-1.5399e+01, -1.4758e+01, -6.6455e+00, -4.8828e+00, -1.4432e+01,\n",
      "         -1.4071e+01, -8.1035e+00, -6.0911e+00, -8.3369e-02, -7.1223e+00,\n",
      "         -2.6924e+00, -1.0889e+01],\n",
      "        [-1.5240e+01, -1.7223e+01, -1.1255e+01, -1.0482e+01, -2.3739e+01,\n",
      "         -9.2744e+00, -1.0975e+01, -8.5332e+00, -9.6674e+00, -4.6062e-04,\n",
      "         -1.0032e+01, -1.2419e+01],\n",
      "        [-3.8762e+00, -1.0764e+01, -3.2019e+00, -5.2809e+00, -9.2111e+00,\n",
      "         -2.3052e+00, -3.8444e+00, -6.8584e+00, -5.8992e+00, -2.1786e-01,\n",
      "         -6.6267e+00, -5.8484e+00],\n",
      "        [-1.0791e+01, -1.5701e+00, -5.2638e+00, -9.5766e+00, -1.4356e+01,\n",
      "         -8.4500e+00, -6.4525e+00, -2.6414e-01, -5.9848e+00, -4.2449e+00,\n",
      "         -9.9083e+00, -8.7783e+00],\n",
      "        [-5.3487e+00, -6.0576e+00, -2.0138e+00, -2.2134e+00, -3.0217e+00,\n",
      "         -6.1768e+00, -1.9633e+00, -2.6844e+00, -1.0275e+00, -4.6228e+00,\n",
      "         -2.1395e+00, -5.2562e+00],\n",
      "        [-7.5858e+00, -1.3548e-02, -6.6582e+00, -1.4248e+01, -1.0313e+01,\n",
      "         -7.3061e+00, -5.7318e+00, -4.9273e+00, -7.7787e+00, -1.1650e+01,\n",
      "         -1.4408e+01, -9.9915e+00],\n",
      "        [-4.5952e+00, -1.4336e+01, -5.7805e+00, -6.9075e+00, -1.6887e-02,\n",
      "         -9.0112e+00, -6.1542e+00, -1.3185e+01, -1.0542e+01, -1.2147e+01,\n",
      "         -8.5695e+00, -9.3604e+00],\n",
      "        [-3.8005e+00, -8.8924e+00, -7.3187e+00, -8.5018e+00, -1.2148e+01,\n",
      "         -8.8982e-02, -4.1248e+00, -8.7026e+00, -6.6527e+00, -3.1319e+00,\n",
      "         -1.2860e+01, -7.5851e+00],\n",
      "        [-8.9866e+00, -1.4286e-03, -7.8416e+00, -2.0184e+01, -1.2265e+01,\n",
      "         -1.0175e+01, -9.3243e+00, -7.1648e+00, -1.5435e+01, -1.4207e+01,\n",
      "         -1.9312e+01, -1.2628e+01],\n",
      "        [-2.0069e+00, -4.2181e+00, -1.0857e+00, -4.1790e+00, -3.5321e+00,\n",
      "         -2.4164e+00, -1.3434e+00, -3.6474e+00, -2.9882e+00, -3.6393e+00,\n",
      "         -5.7346e+00, -4.3815e+00],\n",
      "        [-1.0462e+00, -9.0066e+00, -8.3763e-01, -3.5434e+00, -6.5452e+00,\n",
      "         -2.3676e+00, -6.6936e+00, -7.9448e+00, -1.2451e+01, -2.4361e+00,\n",
      "         -1.5755e+01, -5.9094e+00],\n",
      "        [-1.7411e+00, -7.2700e+00, -5.2519e+00, -9.5577e+00, -9.9932e+00,\n",
      "         -2.4312e-01, -5.4370e+00, -9.0199e+00, -1.1950e+01, -3.5297e+00,\n",
      "         -1.6384e+01, -7.3276e+00],\n",
      "        [-1.0928e+01, -1.3733e+01, -7.8959e+00, -1.3154e+01, -7.2832e+00,\n",
      "         -1.2315e+01, -6.2263e+00, -9.1314e+00, -9.4176e+00, -7.4269e+00,\n",
      "         -3.8776e-03, -1.0637e+01],\n",
      "        [-8.2780e+00, -2.0036e-02, -6.6252e+00, -1.7928e+01, -7.5229e+00,\n",
      "         -1.0188e+01, -6.9255e+00, -4.0994e+00, -1.5629e+01, -9.5865e+00,\n",
      "         -1.1180e+01, -1.0391e+01],\n",
      "        [-4.5592e+00, -1.3989e+01, -6.9345e+00, -1.1513e+01, -1.1803e-02,\n",
      "         -1.0072e+01, -8.8343e+00, -1.3582e+01, -2.1366e+01, -9.8884e+00,\n",
      "         -1.1432e+01, -1.0482e+01],\n",
      "        [-7.4602e-01, -2.8325e+00, -3.9349e+00, -1.2547e+01, -6.1718e+00,\n",
      "         -9.1405e-01, -3.2253e+00, -7.3478e+00, -1.0714e+01, -5.9433e+00,\n",
      "         -1.2942e+01, -6.6342e+00],\n",
      "        [-3.7544e+00, -9.8306e+00, -7.8619e+00, -1.3654e+01, -1.5554e+01,\n",
      "         -5.8365e-02, -6.3336e+00, -1.1380e+01, -1.1649e+01, -3.4760e+00,\n",
      "         -1.6834e+01, -9.0976e+00],\n",
      "        [-3.4578e+00, -3.0997e-01, -3.4071e+00, -1.0124e+01, -1.1319e+01,\n",
      "         -2.3463e+00, -6.6495e+00, -3.3143e+00, -1.3903e+01, -2.6932e+00,\n",
      "         -1.8557e+01, -7.1313e+00],\n",
      "        [-9.8047e+00, -1.6760e+01, -1.3755e+01, -1.6882e+01, -6.3896e-05,\n",
      "         -1.6554e+01, -1.1903e+01, -1.8270e+01, -2.4050e+01, -1.9614e+01,\n",
      "         -1.3918e+01, -1.5900e+01],\n",
      "        [-2.5854e+00, -6.2083e+00, -5.5315e+00, -1.1789e+01, -1.2499e+01,\n",
      "         -1.5300e-01, -5.4965e+00, -8.3577e+00, -1.1719e+01, -2.8878e+00,\n",
      "         -1.6207e+01, -7.6428e+00],\n",
      "        [-2.5817e+00, -5.0441e+00, -4.4210e+00, -8.9607e+00, -1.0817e+01,\n",
      "         -2.7627e-01, -4.3310e+00, -6.1318e+00, -9.1181e+00, -2.0386e+00,\n",
      "         -1.3767e+01, -6.5126e+00],\n",
      "        [-6.6385e+00, -1.1617e-01, -5.7497e+00, -1.5989e+01, -5.0014e+00,\n",
      "         -8.2641e+00, -4.8227e+00, -2.4648e+00, -1.5249e+01, -5.5823e+00,\n",
      "         -6.7790e+00, -8.3947e+00],\n",
      "        [-1.9683e+00, -8.1983e+00, -4.5343e+00, -1.0306e+01, -9.2761e+00,\n",
      "         -2.8697e-01, -3.2747e+00, -8.7366e+00, -7.9205e+00, -2.8339e+00,\n",
      "         -1.0027e+01, -6.5297e+00],\n",
      "        [-8.6616e+00, -1.1949e+01, -6.3055e+00, -3.6755e-03, -7.8608e+00,\n",
      "         -9.4683e+00, -9.4567e+00, -7.5238e+00, -9.4868e+00, -7.7293e+00,\n",
      "         -1.5512e+01, -9.6323e+00],\n",
      "        [-1.4472e+00, -6.0735e+00, -2.9685e+00, -8.9674e+00, -7.8243e+00,\n",
      "         -5.3673e-01, -3.0580e+00, -6.9066e+00, -7.8800e+00, -2.5997e+00,\n",
      "         -1.0123e+01, -5.7447e+00],\n",
      "        [-1.3345e+01, -2.1576e+01, -1.2928e+01, -1.6519e+01, -1.3220e+01,\n",
      "         -1.1874e+01, -7.2919e+00, -1.5361e+01, -7.9095e+00, -8.5871e+00,\n",
      "         -1.2503e-03, -1.3433e+01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "model = model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    inputs = inputs.to('cuda')\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)\n",
    "\n",
    "for epoch in range(10): \n",
    "    print(\"ephoc {}\".format(epoch))\n",
    "    for sentence, tags in training_data:\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix).to('cuda')\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        sentence_in = sentence_in.to('cuda')\n",
    "        tag_scores = model(sentence_in).to('cuda')\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    inputs = inputs.to('cuda')\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for test in test_data:\n",
    "    test_labels.append(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "with torch.no_grad():\n",
    "    for t in test_data:\n",
    "        inputs = prepare_sequence(t[0], word_to_ix)\n",
    "        inputs = inputs.to('cuda')\n",
    "        test_results.append(model(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result 86.287%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test result {}%\".format(round(accuracy(test_labels,test_results),3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
